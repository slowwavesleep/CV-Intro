{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cv3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3mJbX6ZdOh7",
        "colab_type": "text"
      },
      "source": [
        "Обучить СНС с помощью Transfer Learning на датасете Food-101\n",
        "Использовать тонкую настройку существующей предобученной модели и методы аугментации данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33fgHunWb3M_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esoGCTX_c9bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_ds, test_ds, valid_ds), ds_info = tfds.load(\n",
        "    'food101',\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        "    split=['train[:90%]', 'train[90%:]', 'validation']\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFgjuMRN38ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment(image, label):\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.image.random_flip_up_down(image)\n",
        "  image = tf.image.resize(image, (INP_SIZE, INP_SIZE))\n",
        "  return image, label\n",
        "\n",
        "def prepare(image, label):\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  return tf.image.resize(image, (INP_SIZE, INP_SIZE)), label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FxwOoe4e3Uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INP_SIZE = 64\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 224\n",
        "\n",
        "\n",
        "\n",
        "train_ds = train_ds.shuffle(buffer_size=3000)\n",
        "train_ds = train_ds.map(augment)\n",
        "train_ds = train_ds.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "test_ds = test_ds.shuffle(buffer_size=3000)\n",
        "test_ds = test_ds.map(prepare)\n",
        "test_ds = test_ds.batch(128, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59X9c2IF6yPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = ds_info.features['label'].num_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X21E-_5JjeDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a544347e-9eda-42ce-dcf3-353638933ee2"
      },
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(INP_SIZE, INP_SIZE, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        ")\n",
        "\n",
        "base_model.trainable = True \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(out, activation='softmax'),\n",
        "])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGmbG5IyjoKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 0.0001\n",
        "optimizer = tf.keras.optimizers.RMSprop(lr=LEARNING_RATE)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBzg2LDRmKlc",
        "colab_type": "code",
        "outputId": "28a118b0-cb4a-452f-fa8a-500200de55e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.fit(\n",
        "    train_ds,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    validation_data=test_ds)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "304/304 [==============================] - 147s 484ms/step - loss: 4.1956 - accuracy: 0.0979 - val_loss: 5.6893 - val_accuracy: 0.1082\n",
            "Epoch 2/10\n",
            "304/304 [==============================] - 148s 488ms/step - loss: 3.1540 - accuracy: 0.2569 - val_loss: 6.1199 - val_accuracy: 0.1392\n",
            "Epoch 3/10\n",
            "304/304 [==============================] - 148s 486ms/step - loss: 2.7087 - accuracy: 0.3404 - val_loss: 5.0068 - val_accuracy: 0.1891\n",
            "Epoch 4/10\n",
            "304/304 [==============================] - 150s 492ms/step - loss: 2.4271 - accuracy: 0.3965 - val_loss: 4.1617 - val_accuracy: 0.2229\n",
            "Epoch 5/10\n",
            "304/304 [==============================] - 148s 486ms/step - loss: 2.2106 - accuracy: 0.4392 - val_loss: 3.6178 - val_accuracy: 0.2627\n",
            "Epoch 6/10\n",
            "304/304 [==============================] - 149s 490ms/step - loss: 2.0256 - accuracy: 0.4823 - val_loss: 3.1690 - val_accuracy: 0.3026\n",
            "Epoch 7/10\n",
            "304/304 [==============================] - 148s 486ms/step - loss: 1.8494 - accuracy: 0.5247 - val_loss: 3.0297 - val_accuracy: 0.3145\n",
            "Epoch 8/10\n",
            "304/304 [==============================] - 149s 490ms/step - loss: 1.6945 - accuracy: 0.5591 - val_loss: 2.9344 - val_accuracy: 0.3298\n",
            "Epoch 9/10\n",
            "304/304 [==============================] - 149s 491ms/step - loss: 1.5512 - accuracy: 0.5930 - val_loss: 2.8910 - val_accuracy: 0.3363\n",
            "Epoch 10/10\n",
            "304/304 [==============================] - 151s 496ms/step - loss: 1.4268 - accuracy: 0.6251 - val_loss: 2.9116 - val_accuracy: 0.3479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5048434ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPrtDLGzAfT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}